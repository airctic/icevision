{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of getting_started.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "608px",
        "left": "1489px",
        "top": "90px",
        "width": "398.875px"
      },
      "toc_section_display": false,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m85F68n8jXCE"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airctic/icevision/blob/master/notebooks/getting_started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oH3fGSICD7Tx"
      },
      "source": [
        "# Getting started with IceVision\n",
        "![](https://airctic.github.io/icevisionages/iceicevisionpng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iUfYr80nhf15"
      },
      "source": [
        "## Why IceVision?\n",
        "\n",
        "- IceVision is an Object-Detection Framework that connects to different libraries/frameworks such as fastai, Pytorch Lightning, and Pytorch with more to come.\n",
        "\n",
        "- Features a Unified Data API with out-of-the-box support for common annotation formats (COCO, VOC, etc.)\n",
        "\n",
        "- The [IceData repo](https://github.com/airctic/icedata) hosts community maintained parsers and custom datasets \n",
        "\n",
        "- Provides flexible model implementations with pluggable backbones\n",
        "\n",
        "- Helps researchers reproduce, replicate, and go beyond published models\n",
        "\n",
        "- Enables practioners to get moving with object detection technology quickly\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h_EBtaKohf16"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This tutorial walks you through the different steps of training and using a model.\n",
        "\n",
        "The IceVision Framework is an **agnostic framework**. To demonstrate this we will train and use our model with both the [fastai](https://github.com/fastai/fastai), and [pytorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning) libraries.\n",
        "\n",
        "If you are using Google Colab, the GPU runtime should be enabled, but if you experience problems when training your model, you may want to check this.\n",
        "`Runtime` -> `Change runtime type` -> `Hardware accelerator dropdown` -> `GPU`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "orTU9-a7hf17"
      },
      "source": [
        "### Install icevision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j0xxHGBthf17",
        "colab": {},
        "tags": []
      },
      "source": [
        "!pip install icevision[all]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yt2hdPvWD7Ty",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Import the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GkWwmiqTD7T0",
        "colab": {}
      },
      "source": [
        "from icevision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3rf4acKkK3RL"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "IceVision provides handy methods to load a dataset, parse annotations, and more. \n",
        "\n",
        "In the example below, we work with the [PETS dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) to detect cats and dogs in images and identify their species. Loading the PETS dataset is one line code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9xhDVvrkN97w",
        "colab": {}
      },
      "source": [
        "path = datasets.pets.load()\n",
        "path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GEVbMr1KOrFJ"
      },
      "source": [
        "### Parser\n",
        "The `Parser` is one of the most important concepts in IceVision. It allows us to work with **any** annotation format.\n",
        "\n",
        "The basic job of the parser is to convert a custom format to something the library can understand. You might still need to create a custom parser for your own dataset. Fear not! Creating parsers is easy. After you've finished this tutorial, check this [custom parser documentation](https://airctic.github.io/icevision/custom_parser/) to understand how to.\n",
        "\n",
        "IceVision already provides a `parser` for the Pets Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WM5-FirlaIGR",
        "colab": {}
      },
      "source": [
        "class_map = datasets.pets.class_map()\n",
        "class_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KoIK-mx5QoP6",
        "colab": {}
      },
      "source": [
        "parser = datasets.pets.parser(path, class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E5Y-BMUFUdKl"
      },
      "source": [
        "### Split the dataset\n",
        "Next, we define the `train/valid` splits for the data. Let's use random splits for this one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z0qOG45kD7UO",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "data_splitter = RandomSplitter([.8, .2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B22Dj6mHD7UN"
      },
      "source": [
        "### Parse the data\n",
        "Next we `parse()` the dataset using the data splitter. This returns returns 2 lists of records: one for training and another for validation. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tlBlZ_8xUyme",
        "colab": {}
      },
      "source": [
        "train_records, valid_records = parser.parse(data_splitter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V425y7CQWo07"
      },
      "source": [
        "!!! info \"What's a record?\"  \n",
        "    A record is a dictionary that contains all parsed fields defined by the parser used.\n",
        "    No matter what format the annotation has, a record has a common structure that can be connected to different DL frameworks (fastai, Pytorch-Lightning, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SDlPoyCYhf2U"
      },
      "source": [
        "### Visualize the training data\n",
        "\n",
        "We can show one of the records (image + box + label). This helps to understand what is in the dataset and check that the boxes and labels make sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lccxNKoLD7UU",
        "colab": {}
      },
      "source": [
        "show_record(train_records[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "opzFt_vyg904"
      },
      "source": [
        "We can also display the label instead of its identifier by providing the `class_map`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GtGSPnzBa3OU",
        "colab": {}
      },
      "source": [
        "show_record(train_records[1], class_map=class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K32f6Y7xg907"
      },
      "source": [
        "Of course, we often want to see several images with their corresponding boxes and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lfWr7giHUPzB",
        "colab": {}
      },
      "source": [
        "records = train_records[:6]\n",
        "show_records(records, ncols=3, class_map=class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zj3XXoRSD7Ua"
      },
      "source": [
        "## Transforms\n",
        "\n",
        "Data transformations are an essential part of the training pipeline. There are many transformation libraries available including: [albumentations](https://github.com/albumentations-team/albumentations), [solt](https://github.com/MIPT-Oulu/solt), and [torchvision](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image).\n",
        "\n",
        "IceVision supports the widely used [albumentations](https://github.com/albumentations-team/albumentations) library out-of-the-box.\n",
        "\n",
        "It is possible to integrate other transform libraries. You just need to inherit and override all abstract methods of the `Transform` class. We plan to add more to future versions in response to community feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1XiQ6xU2hf2f"
      },
      "source": [
        "It is typical to use different transformations for the training and validation datasets. The `valid_tfms` apply to the validation set. These are minimal - just resizing the image and normalising it. The `train_tfms` typically do data augmentations such as zoom, crop, lighting adjustments, horizontal flips, and so on. These help to reduce the required training set size, reduce overfitting, and produce a more robust model. Icevision makes this easy - all of the bounding boxes are adjusted if needed. For example, zooming in will make the bounding boxes larger. Crops will not cut any bounding boxes.\n",
        "\n",
        "The `presize` parameter helps to improve the resulting image quality. See the [Fast AI Book](https://github.com/fastai/fastbook/blob/master/05_pet_breeds.ipynb\n",
        ") for more details.\n",
        "\n",
        "The `A.Normalize` function applies a set of default normalizations that have been refined over the years on the Imagenet dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7maVsdLbjXEE",
        "colab": {}
      },
      "source": [
        "presize = 512\n",
        "size = 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uULXwukfD7Ub",
        "colab": {}
      },
      "source": [
        "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size), tfms.A.Normalize()])\n",
        "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=size, presize=presize), tfms.A.Normalize()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PmCUX3vFBMfI"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The `Dataset` class combines the records and transforms.\n",
        "\n",
        "To create a `Dataset`, we just need need to pass the parsed records from the previous step along with the transforms.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y-BnJ71aD7Uh",
        "colab": {}
      },
      "source": [
        "train_ds = Dataset(train_records, train_tfms)\n",
        "valid_ds = Dataset(valid_records, valid_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QOyhd5RRCDWg"
      },
      "source": [
        "!!! info \"What does the `Dataset` class  do?\"  \n",
        "    - Prepares the record: For example, in the record we just have a filename that points to the image, it's at this stage that we open the image.  \n",
        "    - Applies the pipeline of transforms to the record prepared in the previous step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cDdBCQ60CSdS"
      },
      "source": [
        "!!! info \"Lazy transforms\"  \n",
        "    Transforms are applied **lazily**, meaning they are only applied when we grab (get) an item.  \n",
        "    This means that, if you have augmentation (random) transforms, each time you get the **same** item from \n",
        "    the dataset you will get a slightly different version of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ziTnrTBY-j_E"
      },
      "source": [
        "!!! danger \"Important\"  \n",
        "    Because we normalized our images with `imagenet_stats`, when displaying transformed images,  we need to denormalize them.  \n",
        "    The `show_sample` function receives an optional argument called `denormalize_fn` that we can be passed: In our case, we pass `denormalize_imagenet`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DSiaco0Sg91K"
      },
      "source": [
        "### Displaying the same image with different transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mp12p4uihf2r",
        "colab": {}
      },
      "source": [
        "samples = [train_ds[3] for _ in range(6)]\n",
        "show_samples(samples, ncols=3, class_map=class_map, denormalize_fn=denormalize_imagenet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sTqjN4aHoFk3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lwp6B7x_D7Ul"
      },
      "source": [
        "## Model\n",
        "\n",
        "In this tutorial, we are learning to predict bounding boxes and classes, but not performing image segmentation. We will use the `FasterRCNN` model. \n",
        "\n",
        "To create the model, we need to specify how many classes our dataset has. This is the length of the `class_map`. Note that the `class_map` includes a value for  `\"background\"` with index 0, which is added behind the scenes by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VN4giweqD7Un",
        "colab": {}
      },
      "source": [
        "model = faster_rcnn.model(num_classes=len(class_map))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjrcofdPrDgL"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "Each model has its own dataloader (a pytorch `DataLoader`) that could be customized: the dataloaders for the RCNN models have a custom collate function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rth_fUmwD7Ut",
        "colab": {}
      },
      "source": [
        "train_dl = faster_rcnn.train_dl(train_ds, batch_size=16, num_workers=4, shuffle=True)\n",
        "valid_dl = faster_rcnn.valid_dl(valid_ds, batch_size=16, num_workers=4, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WRT_bkcBD7U4"
      },
      "source": [
        "## Training\n",
        "\n",
        "IceVision is an agnostic framework meaning it can be plugged to multiple DL frameworks such as [fastai](https://github.com/fastai/fastai), and [pytorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning).  \n",
        "\n",
        "You could also plug it into a new DL frameworks using your own custom code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OJM4uzgxzGIA"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "Metrics are essential for tracking the model progress as it's training.  \n",
        "Here we are going to be using the well established `COCOMetric`, which reports on the mean average precision of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqdAVfcfJ_uP",
        "colab": {}
      },
      "source": [
        "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A3F9T0PYD7VA"
      },
      "source": [
        "### Training with fastai\n",
        "\n",
        "#### Creating a Learner object\n",
        "Creating a fastai compatible `Learner` using the fastai interface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LLTziKBmD7VA",
        "colab": {}
      },
      "source": [
        "learn = faster_rcnn.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RglVQLnKhf24"
      },
      "source": [
        "#### Training the RCNN model using fastai `fine_tune()` method\n",
        "\n",
        "The fastai `fine_tune` method is useful when you have a pre-trained model, which we are using. It does an initial epoch where it freezes everything except its final layers. It then carries on for the indicated number of epochs using a differential learning rate to train the whole model. It adjusts the learning rate both across the layers of the model as well as across the epochs. This can give excellent results with reduced training time.\n",
        "\n",
        "In September 2020, if everything is working, the model might require around 3 minutes per epoch on a free Google Colab server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x2nhyfSPD7VF",
        "colab": {}
      },
      "source": [
        "learn.fine_tune(10, lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7lrkhhRPD7VJ"
      },
      "source": [
        "### Training with Pytorch-Lightning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZrjhsmWDD7VK",
        "colab": {}
      },
      "source": [
        "# import lightning engine provided by the icevision modules\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EuCfskt7D7VO"
      },
      "source": [
        "#### Creating a Pytorch-Lightning (PL) model class\n",
        "It inherits from `RCNNLightningAdapter` and implements the method PL `configure_optimizers`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SWk6ExcCD7VO",
        "colab": {}
      },
      "source": [
        "class LightModel(faster_rcnn.lightning.ModelAdapter):\n",
        "    def configure_optimizers(self):\n",
        "        return SGD(self.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ho754_seD7VS"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Note:**\n",
        "    \n",
        "If you are familiar to working with lightning, you will note that we've been able to skip some of the boilerplate. This is because the IceVision `RCNNLightningAdapter` takes care of it behind the scene. For example, it defines `training_step` and `validation_step`. The adaptor also supports working with `Metric`s.  \n",
        "\n",
        "If you need custom functionality, you can override or re-implement those methods.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4Xt2S9SD7VU",
        "colab": {}
      },
      "source": [
        "# Creating a PL model object\n",
        "light_model = LightModel(model, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SunxbEeFhf3C"
      },
      "source": [
        "#### Training the RCNN model using PL `Trainer.fit()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MCNFsOmajXFp",
        "colab": {}
      },
      "source": [
        "trainer = pl.Trainer(max_epochs=10, gpus=1)\n",
        "trainer.fit(light_model, train_dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-AhMhPFbzS0w"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F8uNLwi-zVht"
      },
      "source": [
        "### Load a model\n",
        "\n",
        "Training the model with `fastai` using `fine_tune` twice and I got led the the following results:  \n",
        "* train_loss: 0.06772  \n",
        "* valid_loss: 0.074435  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3RiEWszY0HHg"
      },
      "source": [
        "#### Using our Trained Weights\n",
        "If you don't want to train the model, you can use our trained weights that we publicly available: You can download them with `torch.hub`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBH_ZiJby0xZ",
        "colab": {}
      },
      "source": [
        "weights_url = \"https://icevisiondels.s3.us-east-2.amazonaws.com/pets.zip\"\n",
        "state_dict = torch.hub.load_state_dict_from_url(weights_url, map_location=torch.device(\"cuda\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VfibzMwotWnR"
      },
      "source": [
        "!!! info \"Note\"  \n",
        "    Typically inference is done on the cpu, this is why we specify the paramater `map_location` to `cpu` when loading the state dict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "174Z6xYMjXF2"
      },
      "source": [
        "\n",
        "Let's recreate the model and load the downloaded weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYa2WCL10otA",
        "colab": {}
      },
      "source": [
        "model = faster_rcnn.model(num_classes=len(class_map))\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYP8N_5EuMYS"
      },
      "source": [
        "The first step for prediction is to have some images, let's grab some random ones from the validation dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aEjh-bkxwmvo"
      },
      "source": [
        "### 11.3- Predict all images at once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ALQ_eJBZsHAm"
      },
      "source": [
        "If you don't have too many images, you can get predictions with a single forward pass.  \n",
        "\n",
        "In case your images don't fit in memory simultaneously, you should predict in batches, the next section shows how to do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0sevKKWnr7jz"
      },
      "source": [
        "For demonstration purposes, let's take download a single image from the internet and see how our model performs on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9AEPFAPGuWhE",
        "colab": {}
      },
      "source": [
        "IMAGE_URL = \"https://petcaramelo.com/wp-content/uploads/2018/06/beagle-cachorro.jpg\"\n",
        "IMG_PATH = \"tmp.jpg\"\n",
        "\n",
        "download_url(IMAGE_URL, IMG_PATH)\n",
        "img = open_img(IMG_PATH)\n",
        "show_img(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NiII43y5uIAx"
      },
      "source": [
        "!!! info \"Try other images!\"  \n",
        "    Change `IMAGE_URL` to point to another image you found on the internet.  \n",
        "    Just be sure to take one of the breeds from `class_map`, or else the model might get confused."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bsPW54TGrnCr"
      },
      "source": [
        "Whenever you have images in memory (numpy arrays) you can use `Dataset.from_images`.  \n",
        "\n",
        "We're going to use the same transforms we used on the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtymIfDXg913",
        "colab": {}
      },
      "source": [
        "infer_ds = Dataset.from_images([img], valid_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cX_Ma4EMucvt"
      },
      "source": [
        "For any model, the prediction steps are always the same, first call `build_infer_batch` and then `predict`.\n",
        "\n",
        "For `faster_rcnn` we have `detection_threshold`, which specifies how confident the model should be to output a bounding box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8S0v8eUYg916",
        "colab": {}
      },
      "source": [
        "batch, samples = faster_rcnn.build_infer_batch(infer_ds)\n",
        "preds = faster_rcnn.predict(model=model, batch=batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SbOLQvyDwr_6"
      },
      "source": [
        "For displaying the predictions, we first need to grab our image from `samples`. We do this instead of using the original images because transforms may have been applied to the image (in fact, in this case, a resize was used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7LaDJAE1xCHA",
        "colab": {}
      },
      "source": [
        "imgs = [sample[\"img\"] for sample in samples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GMI6AkIivnTI"
      },
      "source": [
        "Now we just need to call `show_preds`, to show the image with its corresponding predictions (boxes + labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sxGDdpaMhf3X",
        "colab": {}
      },
      "source": [
        "show_preds(\n",
        "    imgs=imgs,\n",
        "    preds=preds,\n",
        "    class_map=class_map,\n",
        "    denormalize_fn=denormalize_imagenet,\n",
        "    show=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-rd9WrBwylF"
      },
      "source": [
        "### 11.4- Predicting a batch of images\n",
        "\n",
        "Instead of predicting a whole list of images at one, we can process a small batch at the time: This option is more memory efficient: We use `infer_dataloader` \n",
        "\n",
        "Had we have a test dataset, we would have maken our predicition using the batch technique mentionned here above. As an illustrative example, we will predict all images belonging to the validation dataset using the following approach: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ek7G57o4g92A",
        "colab": {}
      },
      "source": [
        "infer_dl = faster_rcnn.infer_dl(valid_ds, batch_size=16)\n",
        "samples, preds = faster_rcnn.predict_dl(model=model, infer_dl=infer_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NpEMagSL0DHH"
      },
      "source": [
        "Same as before, we grab our images from `samples`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AA0aC4vyx66X",
        "colab": {}
      },
      "source": [
        "imgs = [sample[\"img\"] for sample in samples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "obJdrsblyAqn"
      },
      "source": [
        "Let's show the first 6 predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NE-wFdafz8dE",
        "colab": {}
      },
      "source": [
        "show_preds(\n",
        "    imgs=imgs[:6],\n",
        "    preds=preds[:6],\n",
        "    ncols=3,\n",
        "    class_map=class_map,\n",
        "    denormalize_fn=denormalize_imagenet,\n",
        "    show=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nNJLhokWhf3h"
      },
      "source": [
        "## Happy Learning!\n",
        "\n",
        "If you need any assistance, feel free to join our [forum](https://spectrum.chat/mantis)."
      ]
    }
  ]
}