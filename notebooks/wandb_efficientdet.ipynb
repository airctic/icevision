{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/airctic/icevision/blob/master/notebooks/wandb_efficientdet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH3fGSICD7Tx"
   },
   "source": [
    "# [IceVision](https://airctic.com/) meets [W&B](https://wandb.ai/)\n",
    "\n",
    "IceVision + W&B = Agnostic Object Detection Framework with Outstanding Experiments Tracking \n",
    "\n",
    "IceVision fully supports W&B by providing a one-liner API that enables users to track their trained models and display both the predicted and ground truth bounding boxes.\n",
    "\n",
    "W&B makes visualizing and tracking different models performance a highly enjoyable task. Indeed, we are able to monitor the performance of several EfficientDet backbones by changing few lines of code and obtaining very intuitive and easy-to-interpret figures that highlights both the similarities and differences between the different backbones.\n",
    "\n",
    "For more information check the [Report](https://wandb.ai/ai-fast-track/icevision-fridge/reports/IceVision-meets-W-B--VmlldzoyODQxNjg). Note, however, that the report refers to an older version of IceVision. This tutorial is updated for IceVision 0.7.\n",
    "\n",
    "This tutorial emphasizes the additional work required to integrated W&B. If you are new to IceVision, then we suggest that you look at the [getting started with object detection tutorial](getting_started_object_detection.ipynb).\n",
    "\n",
    "In this tutorial, we are using the [fastai](https://github.com/fastai/fastai) library training loop, the [efficientdet]() object detection model, and a sample dataset with images of objects that you might find in a fridge. Following the usual practice with IceVision, you can use W&B with other training loops, model libraries, models and backbones. The W&B specific lines below would not need to be changed.\n",
    "\n",
    "![](https://raw.githubusercontent.com/airctic/icevision/master/images/fridge-objects.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orTU9-a7hf17"
   },
   "source": [
    "## Install IceVision and IceData\n",
    "If on Colab run the following cell, else check the [installation instructions](https://airctic.com/dev/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0xxHGBthf17"
   },
   "outputs": [],
   "source": [
    "# IceVision - IceData - MMDetection - YOLO v5 Installation\n",
    "#!wget https://raw.githubusercontent.com/airctic/icevision/master/install_colab.sh\n",
    "#!chmod +x install_colab.sh && ./install_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt2hdPvWD7Ty",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkWwmiqTD7T0"
   },
   "outputs": [],
   "source": [
    "from icevision.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.callback.tracker import SaveModelCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rf4acKkK3RL"
   },
   "source": [
    "## Load the Fridge Objects dataset\n",
    "The fridge Objects dataset is tiny dataset that contains 134 images of 4 classes:\n",
    "- can, \n",
    "- carton, \n",
    "- milk bottle, \n",
    "- water bottle.\n",
    "\n",
    "IceVision provides very handy methods such as loading a dataset, parsing annotations, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xhDVvrkN97w"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "url = \"https://cvbp-secondary.z19.web.core.windows.net/datasets/object_detection/odFridgeObjects.zip\"\n",
    "dest_dir = \"fridge\"\n",
    "data_dir = icedata.load_data(url, dest_dir, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WM5-FirlaIGR"
   },
   "outputs": [],
   "source": [
    "# Parser\n",
    "class_map = ClassMap([\"milk_bottle\", \"carton\", \"can\", \"water_bottle\"])\n",
    "parser = parsers.VOCBBoxParser(annotations_dir=data_dir / \"odFridgeObjects/annotations\",\n",
    "                     images_dir=data_dir / \"odFridgeObjects/images\",\n",
    "                     class_map=class_map)\n",
    "# Records\n",
    "train_records, valid_records = parser.parse(show_pbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XiQ6xU2hf2f"
   },
   "source": [
    "## Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_Au4CUgrqU_"
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "image_size = 384\n",
    "\n",
    "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-BnJ71aD7Uh"
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjrcofdPrDgL",
    "tags": []
   },
   "source": [
    "## Create the model\n",
    "In IceVision, we need to select the model type and backbone. For this tutorial, we are selecting efficientdet and the `tf_lite0` backbone. Some models require additional information, such as the `image_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rth_fUmwD7Ut"
   },
   "outputs": [],
   "source": [
    "# Library and model selection\n",
    "\n",
    "model_type = models.ross.efficientdet\n",
    "backbone = model_type.backbones.tf_lite0(pretrained=True)\n",
    "# The efficientdet model requires an img_size parameter\n",
    "extra_args = {'img_size' : image_size}\n",
    "\n",
    "model = efficientdet.model(backbone=backbone, num_classes=len(class_map), **extra_args) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataloaders\n",
    "\n",
    "The dataloaders differ somewhat across the model_types, so creating them comes after selecting the model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_dl = model_type.train_dl(train_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=16, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py_DLC0zD7U6"
   },
   "source": [
    "# Training\n",
    "\n",
    "## Intialize W&B\n",
    "\n",
    "At this point, we initialize W&B. This works in the jupyter notebook, but it is more typical run W&B from within a programme. This is partly because it enables you to track the progress of your training jobs from a custom dashboard from your browser, tablet, or phone. The full interface also makes it easy to compare multiple training runs, which can be very powerful when combined with IceVision. You can easily see which model is best suited to your problem.\n",
    "\n",
    "Initializing is a single line from the W&B library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "MOVAJ5BOhnjj",
    "outputId": "fd587cd6-ba69-4b98-f285-12d8e04cd7a8"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"icevision-fridge\", name=\"efficientdet_tf_lite0\", reinit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the learner\n",
    "\n",
    "This tutorial is using[fastai](https://github.com/fastai/fastai), but IceVision lets you us other frameworks such as  [pytorch-lightning](https://github.com/PyTorchLightning/pytorch-lightning).\n",
    "\n",
    "In order to use W&B within fastai, you need to specify the `WandbCallback`, which results in logging the metrics as well as other key parameters, as well as the `SaveModelCallback`, which enables W&B to log the models. Logging the model is very powerful, as it ensures that you have a copy of the best version of the model as you train. If you are using W&B on-line, however, it causes your model to be transferred to the W&B database as well as saved in a local `wandb` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vwXZIfaFoCU"
   },
   "outputs": [],
   "source": [
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, \n",
    "                                  metrics=[COCOMetric(metric_type=COCOMetricType.bbox)], \n",
    "                                  cbs=[WandbCallback(), SaveModelCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "In this case, we use the `fit_one_cycle` training method from fastai, which uses a specific policy for adjusting the learning rate. This model is likely to take around 2-10 seconds per epoch, depending on your hardware. Training for 30 epochs on this small dataset typically reaches a level around 0.8 (COCOMetric), which is sufficient for our demonstration purposes and saves some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFlmI-R2P-lg"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c9JGx-GvpRp"
   },
   "source": [
    "## Show results\n",
    "\n",
    "We can now look athe results of the training in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "id": "y0yevFs2vn5i",
    "outputId": "92fb0e24-db5a-46a3-c359-8738a680adb8"
   },
   "outputs": [],
   "source": [
    "model_type.show_results(model, valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions\n",
    "\n",
    "Let's get the list of predictions from our model. We do this by creating an `infer_dl` - a dataloader used for inference and then getting predictions from the data loader. \n",
    "\n",
    "Please note the `keep_images=True`. By default, the predictions include scores, labels, and bounding boxes. In our case, we want to keep the images so that we log them to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dl = model_type.infer_dl(valid_ds, batch_size=8)\n",
    "preds = model_type.predict_from_dl(model=model, infer_dl=infer_dl, keep_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBmiIPWXjGoD"
   },
   "source": [
    "## Log results to W&B\n",
    "\n",
    "Now comes the most important bit of this tutorial - actually logging the predictions to W&B. This takes one line specific to icevision and a second line to send the information to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvwYN6sfYp8P"
   },
   "outputs": [],
   "source": [
    "# Create wandb_images for each prediction\n",
    "wandb_images = wandb_img_preds(preds, add_ground_truth=True) \n",
    "\n",
    "# Log the wandb_images to wandb\n",
    "wandb.log({\"Predicted images\": wandb_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After logging and finishing the training, it is good to mark the run as completed. This can take a few seconds, as we wait for the W&B processes to transfer data and finalize logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7VcU2Hhiks9"
   },
   "outputs": [],
   "source": [
    "# optional: mark the run as completed\n",
    "wandb.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNJLhokWhf3h"
   },
   "source": [
    "## Happy Learning!\n",
    "\n",
    "If you need any assistance, feel free to join our [forum](https://discord.gg/JDBeZYK)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "wandb_efficientdet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "608px",
    "left": "1489px",
    "top": "90px",
    "width": "398.875px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
